{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('C:/Users/dhira/Downloads/FruitDetection/FruitClassification'):\n",
    "    for filename in filenames:\n",
    "        #print(os.path.join(dirname, filename))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensor flow libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.xception import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Preprocessing Data\n",
    "\n",
    "#### Loaded and preprocessed the data using the ImageDataGenerator class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an ImageDataGenerator object for the training dataset\n",
    "#### The rescale argument rescales the pixel values from [0, 255] to [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a data generator for the training dataset\n",
    "#### - flow_from_directory loads images from the specified directory\n",
    "#### - target_size resizes all images to 224x224 pixels\n",
    "#### - batch_size determines the number of images generated per batch\n",
    "#### - class_mode='categorical' specifies that the labels are categorical (one-hot encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3115 images belonging to 36 classes.\n",
      "Found 351 images belonging to 36 classes.\n",
      "Found 359 images belonging to 36 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\"C:/Users/dhira/Downloads/FruitDetection/FruitClassification/train\", target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
    "valid_generator = valid_datagen.flow_from_directory('C:/Users/dhira/Downloads/FruitDetection/fruitClassification/validation', target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
    "test_generator = test_datagen.flow_from_directory('C:/Users/dhira/Downloads/FruitDetection/fruitClassification/test', target_size=(224, 224), batch_size=32, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary libraries and models for deep learning tasks, including InceptionV3, ResNet50, VGG16, DenseNet121, EfficientNetB0, and Xception, along with supporting modules for model creation, data preprocessing, and numerical computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications import Xception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the DenseNet121 model with pre-trained weights from ImageNet, excluding the top fully connected layers, and specifying an input shape of 224x224 pixels with 3 color channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = DenseNet121(weights='imagenet', include_top=False,input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the output of the base model\n",
    "x = base_model.output\n",
    "\n",
    "# Apply global average pooling to reduce the feature dimensions and retain only the most relevant features.\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add a dense layer with 512 units and ReLU activation for further processing of the pooled features.\n",
    "x = Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a final dense layer with 36 units and softmax activation to output probabilities for 36 different classes.\n",
    "predictions = Dense(36, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Keras model by specifying the input from the base model and the output as the predictions layer, effectively combining the base model and the custom layers for classification.\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all layers in the base model to non-trainable, freezing their weights during training, so only the custom layers added on top will be trained.\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with the Adam optimizer, using categorical crossentropy as the loss function for multi-class classification, and track accuracy as the performance metric.\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
